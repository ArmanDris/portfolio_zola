<?xml version="1.0" encoding="UTF-8"?>
<feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en">
    <title>Arman - Python</title>
    <subtitle>Personal site, using Zola&#x27;s Duckquill theme.</subtitle>
    <link rel="self" type="application/atom+xml" href="/tags/python/atom.xml"/>
    <link rel="alternate" type="text/html" href="/"/>
    <generator uri="https://www.getzola.org/">Zola</generator>
    <updated>2024-07-27T00:00:00+00:00</updated>
    <id>/tags/python/atom.xml</id>
    <entry xml:lang="en">
        <title>Dino Match</title>
        <published>2024-07-27T00:00:00+00:00</published>
        <updated>2024-07-27T00:00:00+00:00</updated>
        
        <author>
          <name>
            Arman Drismir
          </name>
        </author>
        
        <link rel="alternate" type="text/html" href="/projects/dino-match/"/>
        <id>/projects/dino-match/</id>
        
        <content type="html" xml:base="/projects/dino-match/">&lt;p&gt;
Dino match is a very cool project that mixes facebook&#x27;s Dino vector embedder, Qdrant a vector database, and Svelte Kit a frontend web framework.
&lt;&#x2F;p&gt;
&lt;p&gt;
By combining all of these into a Flask app I am able to perform reverse image searches!
&lt;&#x2F;p&gt;
&lt;p&gt;
The app works by creating vector embeddings for all of the data in its &lt;b&gt;data&lt;&#x2F;b&gt; folder. The app then uploads the embeddings to QDrant. After QDrant has all the embeddings then the webstie is served. When a client opens the site it requests sample images to be sent by the backend. It then displays the sample images for the user. When the user clicks &quot;Run Similarity Search&quot; the image is Base64 encoded again and sent to the backend. Once the backend has the image it creates an embedding with it and queries QDrant using the embedding. Qdrant then responds with similar image embeddings and the backend sends these images back to the front end.
&lt;&#x2F;p&gt;
&lt;p&gt;
Since the backend can receive any Base64 encoded image a crafty user could easily send their own images to run similarity searches on. This also means that a small update could let users upload their own images but I doubt ill ever get to implementing that.
&lt;&#x2F;p&gt;
</content>
        
    </entry>
    <entry xml:lang="en">
        <title>Default Detector</title>
        <published>2024-06-01T00:00:00+00:00</published>
        <updated>2024-06-01T00:00:00+00:00</updated>
        
        <author>
          <name>
            Arman Drismir
          </name>
        </author>
        
        <link rel="alternate" type="text/html" href="/projects/default-detector/"/>
        <id>/projects/default-detector/</id>
        
        <content type="html" xml:base="/projects/default-detector/">&lt;p&gt;I built a svelte&#x2F;flask app around the ML model I made for a CPSC 330 class project.&lt;&#x2F;p&gt;
&lt;div&gt;
   &lt;h2&gt;Dataset &amp;amp; Metrics&lt;&#x2F;h2&gt;
   &lt;p&gt;This dataset is imbalanced, 22% of clients default while 78% do not. For
      this reason F1 score and Recall are the metrics we want to pay a lot of
      attention to. F1 score will give us a good indication of overall
      performance and Recall will tell us how well our model preforms when it
      sees the clients who do default.
   &lt;&#x2F;p&gt;
   &lt;p&gt;The Kaggle page has descriptions for what values in the columns
      represent. &lt;a href=&quot;https:&#x2F;&#x2F;www.kaggle.com&#x2F;datasets&#x2F;uciml&#x2F;default-of-credit-card-clients-dataset&quot; target=&quot;_blank&quot; class=&quot;underline&quot;&gt;Link to dataset.&lt;&#x2F;a&gt;
   &lt;&#x2F;p&gt;
   &lt;h2&gt;Best Model&lt;&#x2F;h2&gt;
   &lt;p&gt;I was able to get a test accuracy of 82% using CatBoost with
      hyperparameters I found using RandomizedSearch. The results were less
      than I expected since a dummy classifier scores 78%. Running
      RandomizedSearch on a more powerful computer would have probably allowed
      me to squeeze a few more points of accuracy. The overall f1, recall, and
      precision scores are good but when looking specifically at the default
      class they are very bad. It would be interesting to train a new model
      that sacrifices accuracy for recall in the DEFAULT class.
   &lt;&#x2F;p&gt;
   &lt;table&gt;
      &lt;tbody&gt;
         &lt;tr&gt;
            &lt;th&gt;&lt;&#x2F;th&gt;
            &lt;th&gt;precision&lt;&#x2F;th&gt;
            &lt;th&gt;recall&lt;&#x2F;th&gt;
            &lt;th&gt;f1-score&lt;&#x2F;th&gt;
         &lt;&#x2F;tr&gt;
         &lt;tr&gt;
            &lt;td&gt;PAID&lt;&#x2F;td&gt;
            &lt;td&gt;0.84&lt;&#x2F;td&gt;
            &lt;td&gt;0.95&lt;&#x2F;td&gt;
            &lt;td&gt;0.89&lt;&#x2F;td&gt;
         &lt;&#x2F;tr&gt;
         &lt;tr&gt;
            &lt;td&gt;DEFAULT&lt;&#x2F;td&gt;
            &lt;td&gt;0.68&lt;&#x2F;td&gt;
            &lt;td&gt;0.37&lt;&#x2F;td&gt;
            &lt;td&gt;0.48&lt;&#x2F;td&gt;
         &lt;&#x2F;tr&gt;
         &lt;tr&gt;
            &lt;td&gt;average&lt;&#x2F;td&gt;
            &lt;td&gt;0.81&lt;&#x2F;td&gt;
            &lt;td&gt;0.82&lt;&#x2F;td&gt;
            &lt;td&gt;0.80&lt;&#x2F;td&gt;
         &lt;&#x2F;tr&gt;
      &lt;&#x2F;tbody&gt;
   &lt;&#x2F;table&gt;
   &lt;h2&gt;All Models&lt;&#x2F;h2&gt;
   &lt;h3&gt;Linear Regression&lt;&#x2F;h3&gt;
   &lt;p&gt;Train score: 0.810524, improved to 0.8106 with HPO &lt;span style=&quot;color: #859900;&quot;&gt;(+0.000076)&lt;&#x2F;span&gt;.&lt;&#x2F;p&gt;
   &lt;h3&gt;SVC&lt;&#x2F;h3&gt;
   &lt;p&gt;Train score: 0.8177, improved to 0.8183 with HPO &lt;span style=&quot;color: #859900;&quot;&gt;(+0.0006)&lt;&#x2F;span&gt;&lt;&#x2F;p&gt;
   &lt;h3&gt;Gradient Boosted Trees&lt;&#x2F;h3&gt;
   &lt;p&gt;Train score: 0.8190, decreased to 0.8189 with HPO &lt;span style=&quot;color: #dc322f&quot;&gt;(-0.0001)&lt;&#x2F;span&gt;&lt;&#x2F;p&gt;
   &lt;h3&gt;CatBoost&lt;&#x2F;h3&gt;
   &lt;p&gt;Train score: 0.8175, improved to 0.8214 with HPO &lt;span style=&quot;color: #859900;&quot; &gt;(+0.0039)&lt;&#x2F;span&gt;&lt;&#x2F;p&gt;
&lt;&#x2F;div&gt;
</content>
        
    </entry>
    <entry xml:lang="en">
        <title>LinkedIn Scraper</title>
        <published>2024-01-20T00:00:00+00:00</published>
        <updated>2024-01-20T00:00:00+00:00</updated>
        
        <author>
          <name>
            Arman Drismir
          </name>
        </author>
        
        <link rel="alternate" type="text/html" href="/work/linkedin-scraper/"/>
        <id>/work/linkedin-scraper/</id>
        
        <content type="html" xml:base="/work/linkedin-scraper/">&lt;p&gt;Using the LinkedIn API to get jobs postings was a bit of an art. To organize my efforts this is the report I made with my method and results.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;fetch-jobs-report&quot;&gt;Fetch Jobs Report&lt;&#x2F;h2&gt;
&lt;h3 id=&quot;problem&quot;&gt;Problem:&lt;&#x2F;h3&gt;
&lt;p&gt;Dealing with LinkedIn’s rate limiting is very hard. It is very unclear what causes rate limiting.&lt;&#x2F;p&gt;
&lt;h3 id=&quot;solution&quot;&gt;Solution:&lt;&#x2F;h3&gt;
&lt;p&gt;It seems LinkedIn’s rate limiting is not influenced much by frequency. Using proxies does not work well since the free proxy lists I was scraping were very poor quality(90% broken). A very effective solution is to handle failures gracefully. I try each request 7 times one after another. This improves request success from ~20% to ~99%. Even if I still fail to fetch a job posting I still don’t stop, I just remove the job posting from the list and continue. Another important solution is to clearly differentiate between HTML parsing errors and failed requests. Failed requests are unfixable but failed parsing is. Now I have a ~99% success rate with html parsing which means I do not waste time waiting for a request I will not even be able to use.&lt;&#x2F;p&gt;
&lt;h3 id=&quot;results&quot;&gt;Results:&lt;&#x2F;h3&gt;
&lt;ul&gt;
&lt;li&gt;5 job postings went from &lt;strong&gt;~18&lt;&#x2F;strong&gt; seconds to &lt;strong&gt;~4.7&lt;&#x2F;strong&gt;&lt;&#x2F;li&gt;
&lt;li&gt;Success rate went from &lt;strong&gt;~20%&lt;&#x2F;strong&gt; to &lt;strong&gt;~99%&lt;&#x2F;strong&gt;&lt;&#x2F;li&gt;
&lt;li&gt;These were accomplished by:
&lt;ul&gt;
&lt;li&gt;Perfecting HTML parsing. &lt;strong&gt;~100%&lt;&#x2F;strong&gt; of requests are successfully parsed&lt;&#x2F;li&gt;
&lt;li&gt;Do not hard fail on failed request. Instead try up to 7 times before abandoning request&lt;&#x2F;li&gt;
&lt;li&gt;Do not hard fail on abandoned requests. Instead remove job from array and continue&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
</content>
        
    </entry>
</feed>
